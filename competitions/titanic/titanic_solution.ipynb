{
    "cells": [
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "# üö¢ Titanic - Complete Solution\n",
                "\n",
                "**Goal**: Predict survival on the Titanic (Binary Classification)\n",
                "\n",
                "**Metric**: Accuracy\n",
                "\n",
                "---"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## üì¶ Setup"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [
                {
                    "ename": "",
                    "evalue": "",
                    "output_type": "error",
                    "traceback": [
                        "\u001b[1;31mRunning cells with '.venv (Python 3.14.2)' requires the ipykernel package.\n",
                        "\u001b[1;31mInstall 'ipykernel' into the Python environment. \n",
                        "\u001b[1;31mCommand: 'c:/Users/anish/Desktop/kaggle/.venv/Scripts/python.exe -m pip install ipykernel -U --force-reinstall'"
                    ]
                }
            ],
            "source": [
                "import sys\n",
                "sys.path.append('../../..')\n",
                "\n",
                "import pandas as pd\n",
                "import numpy as np\n",
                "import matplotlib.pyplot as plt\n",
                "import seaborn as sns\n",
                "from sklearn.model_selection import cross_val_score, StratifiedKFold\n",
                "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
                "from sklearn.linear_model import LogisticRegression\n",
                "from sklearn.preprocessing import LabelEncoder\n",
                "\n",
                "# Our shared utilities\n",
                "from shared.utils import set_seed\n",
                "from shared.auto_eda import quick_eda\n",
                "\n",
                "set_seed(42)\n",
                "plt.style.use('seaborn-v0_8-whitegrid')\n",
                "\n",
                "%matplotlib inline"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## üìÇ Load Data"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "train = pd.read_csv('data/raw/train.csv')\n",
                "test = pd.read_csv('data/raw/test.csv')\n",
                "\n",
                "print(f\"Train: {train.shape}\")\n",
                "print(f\"Test: {test.shape}\")\n",
                "\n",
                "# Save test IDs for submission\n",
                "test_ids = test['PassengerId']"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "train.head()"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "train.info()"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## üîç Quick Automated EDA"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Run our automated EDA\n",
                "report = quick_eda(train, target_col='Survived')"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## üìä Survival Analysis"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "fig, axes = plt.subplots(2, 3, figsize=(15, 10))\n",
                "\n",
                "# Survival rate\n",
                "train['Survived'].value_counts().plot(kind='bar', ax=axes[0,0], color=['#ff6b6b', '#51cf66'])\n",
                "axes[0,0].set_title('Survival Count')\n",
                "axes[0,0].set_xticklabels(['Died', 'Survived'], rotation=0)\n",
                "\n",
                "# By Sex\n",
                "train.groupby('Sex')['Survived'].mean().plot(kind='bar', ax=axes[0,1], color=['#ff6b6b', '#51cf66'])\n",
                "axes[0,1].set_title('Survival Rate by Sex')\n",
                "axes[0,1].set_ylabel('Survival Rate')\n",
                "axes[0,1].tick_params(rotation=0)\n",
                "\n",
                "# By Pclass\n",
                "train.groupby('Pclass')['Survived'].mean().plot(kind='bar', ax=axes[0,2], color='steelblue')\n",
                "axes[0,2].set_title('Survival Rate by Class')\n",
                "axes[0,2].set_ylabel('Survival Rate')\n",
                "axes[0,2].tick_params(rotation=0)\n",
                "\n",
                "# Age distribution\n",
                "train[train['Survived']==1]['Age'].hist(ax=axes[1,0], bins=30, alpha=0.7, label='Survived', color='#51cf66')\n",
                "train[train['Survived']==0]['Age'].hist(ax=axes[1,0], bins=30, alpha=0.7, label='Died', color='#ff6b6b')\n",
                "axes[1,0].set_title('Age Distribution by Survival')\n",
                "axes[1,0].legend()\n",
                "\n",
                "# By Embarked\n",
                "train.groupby('Embarked')['Survived'].mean().plot(kind='bar', ax=axes[1,1], color='steelblue')\n",
                "axes[1,1].set_title('Survival Rate by Embarked')\n",
                "axes[1,1].tick_params(rotation=0)\n",
                "\n",
                "# Fare distribution\n",
                "train['Fare'].hist(ax=axes[1,2], bins=50, color='steelblue')\n",
                "axes[1,2].set_title('Fare Distribution')\n",
                "\n",
                "plt.tight_layout()\n",
                "plt.show()"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## üßπ Feature Engineering"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "def engineer_features(df):\n",
                "    \"\"\"Feature engineering for Titanic dataset.\"\"\"\n",
                "    df = df.copy()\n",
                "    \n",
                "    # --- Extract Title from Name ---\n",
                "    df['Title'] = df['Name'].str.extract(r' ([A-Za-z]+)\\.')\n",
                "    \n",
                "    # Group rare titles\n",
                "    title_mapping = {\n",
                "        'Mr': 'Mr', 'Miss': 'Miss', 'Mrs': 'Mrs', 'Master': 'Master',\n",
                "        'Rev': 'Rare', 'Dr': 'Rare', 'Col': 'Rare', 'Major': 'Rare',\n",
                "        'Mlle': 'Miss', 'Mme': 'Mrs', 'Ms': 'Miss', 'Lady': 'Rare',\n",
                "        'Sir': 'Rare', 'Capt': 'Rare', 'Countess': 'Rare', 'Don': 'Rare',\n",
                "        'Jonkheer': 'Rare', 'Dona': 'Rare'\n",
                "    }\n",
                "    df['Title'] = df['Title'].map(title_mapping).fillna('Rare')\n",
                "    \n",
                "    # --- Family Features ---\n",
                "    df['FamilySize'] = df['SibSp'] + df['Parch'] + 1\n",
                "    df['IsAlone'] = (df['FamilySize'] == 1).astype(int)\n",
                "    \n",
                "    # --- Age Groups ---\n",
                "    # Fill missing ages with median by Title\n",
                "    df['Age'] = df.groupby('Title')['Age'].transform(lambda x: x.fillna(x.median()))\n",
                "    df['Age'] = df['Age'].fillna(df['Age'].median())  # Fallback\n",
                "    \n",
                "    df['AgeGroup'] = pd.cut(df['Age'], bins=[0, 12, 18, 35, 60, 100], \n",
                "                            labels=['Child', 'Teen', 'Adult', 'Middle', 'Senior'])\n",
                "    df['IsChild'] = (df['Age'] < 12).astype(int)\n",
                "    \n",
                "    # --- Fare ---\n",
                "    df['Fare'] = df['Fare'].fillna(df['Fare'].median())\n",
                "    df['FarePerPerson'] = df['Fare'] / df['FamilySize']\n",
                "    df['FareBin'] = pd.qcut(df['Fare'], 4, labels=['Low', 'Mid', 'High', 'VeryHigh'], duplicates='drop')\n",
                "    \n",
                "    # --- Cabin ---\n",
                "    df['HasCabin'] = df['Cabin'].notna().astype(int)\n",
                "    df['Deck'] = df['Cabin'].str[0].fillna('Unknown')\n",
                "    \n",
                "    # --- Embarked ---\n",
                "    df['Embarked'] = df['Embarked'].fillna('S')  # Most common\n",
                "    \n",
                "    # --- Sex ---\n",
                "    df['Sex'] = (df['Sex'] == 'male').astype(int)\n",
                "    \n",
                "    return df"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Apply feature engineering\n",
                "train_fe = engineer_features(train)\n",
                "test_fe = engineer_features(test)\n",
                "\n",
                "print(f\"Train shape after FE: {train_fe.shape}\")\n",
                "print(f\"New features: {[c for c in train_fe.columns if c not in train.columns]}\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## üîß Prepare Final Features"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Features to use\n",
                "FEATURES = [\n",
                "    'Pclass', 'Sex', 'Age', 'SibSp', 'Parch', 'Fare',\n",
                "    'FamilySize', 'IsAlone', 'IsChild', 'HasCabin', 'FarePerPerson'\n",
                "]\n",
                "\n",
                "# Categorical features to encode\n",
                "CAT_FEATURES = ['Title', 'Embarked', 'AgeGroup', 'FareBin', 'Deck']\n",
                "\n",
                "# Encode categoricals\n",
                "all_data = pd.concat([train_fe, test_fe], ignore_index=True)\n",
                "\n",
                "for col in CAT_FEATURES:\n",
                "    le = LabelEncoder()\n",
                "    all_data[col] = le.fit_transform(all_data[col].astype(str))\n",
                "    train_fe[col] = le.transform(train_fe[col].astype(str))\n",
                "    test_fe[col] = le.transform(test_fe[col].astype(str))\n",
                "\n",
                "ALL_FEATURES = FEATURES + CAT_FEATURES\n",
                "\n",
                "X = train_fe[ALL_FEATURES]\n",
                "y = train_fe['Survived']\n",
                "X_test = test_fe[ALL_FEATURES]\n",
                "\n",
                "print(f\"Final features: {len(ALL_FEATURES)}\")\n",
                "print(f\"X: {X.shape}, y: {y.shape}, X_test: {X_test.shape}\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## ü§ñ Model Training"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Define models\n",
                "models = {\n",
                "    'Logistic Regression': LogisticRegression(max_iter=1000, random_state=42),\n",
                "    'Random Forest': RandomForestClassifier(n_estimators=200, max_depth=5, random_state=42),\n",
                "    'Gradient Boosting': GradientBoostingClassifier(n_estimators=100, max_depth=4, random_state=42)\n",
                "}\n",
                "\n",
                "# Cross-validation\n",
                "cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
                "\n",
                "results = {}\n",
                "for name, model in models.items():\n",
                "    scores = cross_val_score(model, X, y, cv=cv, scoring='accuracy')\n",
                "    results[name] = scores\n",
                "    print(f\"{name:25s} | CV Accuracy: {scores.mean():.4f} (+/- {scores.std():.4f})\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Visualize results\n",
                "plt.figure(figsize=(10, 5))\n",
                "plt.boxplot(results.values(), labels=results.keys())\n",
                "plt.title('Model Comparison (5-Fold CV)')\n",
                "plt.ylabel('Accuracy')\n",
                "plt.ylim(0.75, 0.90)\n",
                "plt.show()"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## üéØ Train Final Model & Predict"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Use best model (typically Random Forest or Gradient Boosting)\n",
                "final_model = GradientBoostingClassifier(n_estimators=150, max_depth=4, random_state=42)\n",
                "final_model.fit(X, y)\n",
                "\n",
                "# Feature importance\n",
                "importance = pd.DataFrame({\n",
                "    'feature': ALL_FEATURES,\n",
                "    'importance': final_model.feature_importances_\n",
                "}).sort_values('importance', ascending=False)\n",
                "\n",
                "plt.figure(figsize=(10, 6))\n",
                "plt.barh(importance['feature'], importance['importance'], color='steelblue')\n",
                "plt.xlabel('Importance')\n",
                "plt.title('Feature Importance')\n",
                "plt.gca().invert_yaxis()\n",
                "plt.tight_layout()\n",
                "plt.show()"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Make predictions\n",
                "predictions = final_model.predict(X_test)\n",
                "\n",
                "print(f\"Predictions shape: {predictions.shape}\")\n",
                "print(f\"Survival rate: {predictions.mean():.2%}\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## üì§ Create Submission"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Create submission file\n",
                "submission = pd.DataFrame({\n",
                "    'PassengerId': test_ids,\n",
                "    'Survived': predictions\n",
                "})\n",
                "\n",
                "# Verify format\n",
                "print(f\"Submission shape: {submission.shape}\")\n",
                "print(f\"Expected: (418, 2)\")\n",
                "print(f\"\\nColumns: {submission.columns.tolist()}\")\n",
                "submission.head(10)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Save submission\n",
                "import os\n",
                "os.makedirs('submissions', exist_ok=True)\n",
                "\n",
                "submission.to_csv('submissions/submission.csv', index=False)\n",
                "print(\"‚úÖ Submission saved to submissions/submission.csv\")\n",
                "\n",
                "# Quick sanity check\n",
                "check = pd.read_csv('submissions/submission.csv')\n",
                "print(f\"\\nüìä Sanity Check:\")\n",
                "print(f\"   Rows: {len(check)} (expected 418)\")\n",
                "print(f\"   Columns: {check.columns.tolist()}\")\n",
                "print(f\"   Survived 0s: {(check['Survived']==0).sum()}\")\n",
                "print(f\"   Survived 1s: {(check['Survived']==1).sum()}\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "---\n",
                "\n",
                "## üéâ Done!\n",
                "\n",
                "Your submission file is ready at `submissions/submission.csv`.\n",
                "\n",
                "**To submit:**\n",
                "1. Go to [kaggle.com/c/titanic](https://www.kaggle.com/c/titanic)\n",
                "2. Click \"Submit Predictions\"\n",
                "3. Upload `submissions/submission.csv`\n",
                "\n",
                "**Expected accuracy: ~78-80%** (Top 20% on leaderboard)\n",
                "\n",
                "### üí° Ideas to Improve\n",
                "- Try ensemble of multiple models\n",
                "- Add more feature engineering (ticket prefix, name length, etc.)\n",
                "- Use LightGBM or XGBoost\n",
                "- Tune hyperparameters with GridSearchCV"
            ]
        }
    ],
    "metadata": {
        "kernelspec": {
            "display_name": ".venv",
            "language": "python",
            "name": "python3"
        },
        "language_info": {
            "name": "python",
            "version": "3.14.2"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 4
}
